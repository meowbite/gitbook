# 什么是hadoop

hadoop3个核心组件:

- 分布式文件系统：HDFS —— 实现将文件分布式存储在很多的服务器上

- 分布式运算编程框架：MAPREDUCE —— 实现在很多机器上分布式并行运算

- 分布式资源调度平台：YARN —— 帮用户调度大量的mapreduce程序，并合理分配运算资源

hdfs的工作机制:

- 客户把一个文件存入hdfs，其实hdfs会把这个文件切块后，分散存储在N台linux机器系统中（负责存储文件块的角色：data node）<准确来说：切块的行为是由客户端决定的>

- 一旦文件被切块存储，那么，hdfs中就必须有一个机制，来记录用户的每一个文件的切块信息，及每一块的具体存储机器（负责记录块信息的角色是：name node）

- 为了保证数据的安全性，hdfs可以将每一个文件块在集群中存放多个副本（到底存几个副本，是由当时存入该文件的客户端指定的）
